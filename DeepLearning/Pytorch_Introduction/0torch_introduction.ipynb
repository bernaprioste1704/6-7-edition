{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exercises Deep Learning\n",
    "First Lecture"
   ],
   "id": "40e4b959cb62141a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Basic Tensor Operations\n",
   "id": "f843372da6ee2f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T17:22:46.590064Z",
     "start_time": "2025-01-14T17:22:45.586928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ],
   "id": "f59e02c1a624f6b9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x = torch.Tensor(2, 3, 4)",
   "id": "d6b1beb874f2d53c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Different ways to create tensors:\n",
    "- ```torch.zeros```: Creates a tensor filled with zeros\n",
    "- ```torch.ones```: Creates a tensor filled with ones\n",
    "- ```torch.rand```: Creates a tensor with random values uniformly sampled between 0 and 1\n",
    "- ```torch.randn```: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
    "- ```torch.arange```: Creates a tensor containing the values\n",
    "- ```torch.Tensor``` (input list): Creates a tensor from the list elements you provide"
   ],
   "id": "be071422e88e2797"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can obtain the shape of a tensor in the same way as in numpy (```x.shape```), or using the ```.size``` method:",
   "id": "652bfdd9d01d2cab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "shape = x.shape\n",
    "print(\"Shape:\", x.shape)\n",
    "\n",
    "size = x.size()\n",
    "print(\"Size:\", size)\n",
    "\n",
    "dim1, dim2, dim3 = x.size()\n",
    "print(\"Size:\", dim1, dim2, dim3)"
   ],
   "id": "3a5aba3abc981603",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tensor to Numpy, and Numpy to Tensor\n",
   "id": "1919de243a31992c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"Numpy array:\", np_arr)\n",
    "print(\"PyTorch tensor:\", tensor)"
   ],
   "id": "788bf302f6590378",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tensor = torch.arange(4)\n",
    "np_arr = tensor.numpy()\n",
    "\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "print(\"Numpy array:\", np_arr)"
   ],
   "id": "20199e8a5e016e34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Matrix multiplication",
   "id": "f0e78a94d4c6a5f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = torch.arange(6)\n",
    "x = x.view(2, 3)\n",
    "print(\"X\", x)"
   ],
   "id": "6e97615c75ea0e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
    "print(\"W\", W)"
   ],
   "id": "d8c106a45680668e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
    "print(\"h\", h)"
   ],
   "id": "1272a65d6ae9200e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " ### What about gpus?\n",
    "\n",
    "When you create a tensor the tensor is ready to be computed by the cpu. To convert the tensor you can use ```.to()```\n",
    "passing to the function \"cuda\" or \"cpu\" as needed"
   ],
   "id": "721ec6774f26fb13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### How do I know if I have cuda cores on my computer?\n",
    "To solve this you can check with torch if cuda is available:"
   ],
   "id": "3b57528335dc0269"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "example_tensor = torch.rand(2,2)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. You can use GPU for PyTorch.\")\n",
    "    example_tensor.to(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU for PyTorch.\")\n",
    "    example_tensor.to(\"cpu\")"
   ],
   "id": "38113a46a272b80a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exercises",
   "id": "8127a2bc83ad170a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Create two tensors",
   "id": "dbbe4a9ddaf9b81d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "   - A 3x3 tensor of random numbers.\n",
    "   - A 3x3 tensor filled with ones."
   ],
   "id": "964101079da9badd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#Exercise 1",
   "id": "83e1b2cdb8bade78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Perform the following operations",
   "id": "a271b3d5fb87c50b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Add the two tensors.\n",
    "- Multiply the two tensors element-wise.\n",
    "- Compute the dot product between the first row of both tensors.\n",
    " - Find the transpose of the resulting tensor from the element-wise multiplication."
   ],
   "id": "db794d8774eae177"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#Exercise 2",
   "id": "406bfe0aed2719b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Convert the resulting tensor to a NumPy array and back to a PyTorch tensor.",
   "id": "a57afe90005dc29a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#Exercise 3",
   "id": "182f70f0737cff3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Autograd",
   "id": "589117b4a2e3f7cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Create Tensors",
   "id": "a16d9efcf227bb68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_a = torch.tensor(0., requires_grad=True)\n",
    "x_b = torch.tensor(0., requires_grad=True)\n",
    "w_a = torch.tensor(0.9, requires_grad=True)\n",
    "w_b = torch.tensor(0.9, requires_grad=True)\n",
    "\n",
    "y = torch.tensor(0., requires_grad=False)"
   ],
   "id": "be5673134b6e6eec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Build a computation graph",
   "id": "1db0554422da0a80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weighted_a = w_a * x_a\n",
    "weighted_b = w_b * x_b\n",
    "sum_unit = weighted_a + weighted_b"
   ],
   "id": "35fad594fa32a16c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. Activation Function\n",
    "\n",
    "For a simple approach as ease of replication by hand we will this activation function:"
   ],
   "id": "89b928ece0981eb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_hat = torch.sigmoid(sum_unit)",
   "id": "cc171048fa0f693d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Calculate Loss",
   "id": "25082a0d8778158f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss = torch.nn.BCELoss()\n",
    "output = loss(y_hat, y)"
   ],
   "id": "fea378f48b561f17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. Calculate gradients",
   "id": "da4b00ba9c0d510c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "output.backward()",
   "id": "59e67123bb0c02f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6.Print out the gradients",
   "id": "d2607801d848cb5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(x_a.grad)\n",
    "print(x_b.grad)\n",
    "print(w_a.grad)\n",
    "print(w_b.grad)"
   ],
   "id": "fe7b458d47eeedab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Loop",
   "id": "e479bfbd78c7d3e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T17:22:49.794682Z",
     "start_time": "2025-01-14T17:22:49.788011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "input_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "target_data = torch.tensor([[0], [0], [0], [1]], dtype=torch.float32)"
   ],
   "id": "5e7d26b57cd49c3e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T17:22:50.655971Z",
     "start_time": "2025-01-14T17:22:50.652999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ANDGateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANDGateModel, self).__init__()\n",
    "        self.linear = nn.Linear(2, 1,bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n"
   ],
   "id": "122d9dbb9d32cab2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T17:24:38.411499Z",
     "start_time": "2025-01-14T17:24:38.375069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model = ANDGateModel()\n",
    "\n",
    "# Loss function (Binary Cross-Entropy Loss)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# Optimizer (Stochastic Gradient Descent)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    y_hat = model(input_data)\n",
    "    loss = loss_fn(y_hat, target_data)\n",
    "\n",
    "\n",
    "    loss.backward() # Backpropagation\n",
    "    optimizer.step() # Update parameters using the optimizer\n",
    "    optimizer.zero_grad() # Zero the gradients for the next iteration\n",
    "\n",
    "    # Print loss and progress every 1000 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Final weights and bias (optional)\n",
    "print(f\"Final weights: {model.linear.weight.data}\")\n",
    "print(f\"Final bias: {model.linear.bias.data}\")\n",
    "\n",
    "# Test the AND gate\n",
    "with torch.no_grad():\n",
    "    for i in range(len(input_data)):\n",
    "        x_a, x_b = input_data[i]\n",
    "        y_hat = model(torch.tensor([[x_a, x_b]]))  # Model expects a batch\n",
    "        print(f\"Input: {input_data[i].numpy()} -> Predicted Output: {round(y_hat.item())}, Raw Output: {y_hat.item():.4f}\")\n"
   ],
   "id": "99ae9c0e028670fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0887\n",
      "Final weights: tensor([[4.1424, 4.1404]])\n",
      "Final bias: tensor([-6.2845])\n",
      "Input: [0. 0.] -> Predicted Output: 0, Raw Output: 0.0019\n",
      "Input: [0. 1.] -> Predicted Output: 0, Raw Output: 0.1049\n",
      "Input: [1. 0.] -> Predicted Output: 0, Raw Output: 0.1051\n",
      "Input: [1. 1.] -> Predicted Output: 1, Raw Output: 0.8806\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "!!! IMPORTANT: This example has a significant issue: the test set is the same as the training set.\n",
    "This approach is used here solely for ease of explanation and should never be used in a production environment.!!!"
   ],
   "id": "18785f163f5d7904"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exercises",
   "id": "38d64492b0a9f095"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1.Replicate the OR Gate using a Neural Network\n",
    " Objective:\n",
    "- Train a neural network to approximate the function of an OR gate.\n",
    "- Compare how changing the weights or biases impacts the output of the network.\n",
    "\n",
    "Input 1 | Input 2 | Output (OR)\n",
    "| -- | -- | --|\n",
    "0 | 0 | 0\n",
    "0 | 1 | 1\n",
    "1 | 0 | 1\n",
    "1 | 1 | 1\n",
    "\n",
    "1. Create the dataset\n",
    "2. Replicate the architecture from the AND gate example\n",
    "3. Change the loss function from Binary Cross-Entropy to Mean Squared Error"
   ],
   "id": "4a64599701c601b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Code Here",
   "id": "a197f7d767d46a18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html",
   "id": "7c401a9cd9bd0be5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2. Build and train a network\n",
    "1. Build a simple fully connected neural network with the following architecture:\n",
    "    - Input layer with 2 units\n",
    "    - Hidden layer with 4 units and ReLU activation\n",
    "    - Output layer with 1 unit\n",
    "2. Define the following loss function and optimizer:\n",
    "    - Loss: Mean Squared Error (MSE)\n",
    "    - Optimizer: Stochastic Gradient Descent (SGD)\n",
    "\n",
    "The network should mimic $y = 2x_1 + 3x_2$, where $x_1$ and $x_2$ are random inputs"
   ],
   "id": "86fc0ab91a8ed899"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # Define layers here\n",
    "        self.layer1 =   # Input to hidden layer\n",
    "        self.activation_function =   # Activation function\n",
    "        self.layer2 =   # Hidden to output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define forward pass\n",
    "        x =\n",
    "        x =\n",
    "        x =\n",
    "        return x\n",
    "\n",
    "# Create synthetic data\n",
    "x = torch.rand(100, 2)\n",
    "y = 2 * x[:, 0] + 3 * x[:, 1]\n",
    "y = y.view(-1, 1)\n",
    "\n",
    "# Split data into training and test sets (80% train, 20% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleNet()\n",
    "criterion =   # Loss function (MSE)\n",
    "optimizer =   # Optimizer (SGD)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    # Compute loss\n",
    "    loss =   # Compute loss using criterion\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(x_test)  # Get predictions for the test set\n",
    "    test_loss = criterion(y_test_pred, y_test)  # Compute test loss\n",
    "\n",
    "    print(f'Test Loss: {test_loss.item()}')\n",
    "\n",
    "# Show some final predictions\n",
    "print(\"Final Predictions (first 5 test samples):\")\n",
    "for i in range(5):\n",
    "    print(f\"Predicted: {y_test_pred[i].item():.4f}, Actual: {y_test[i].item():.4f}\")\n",
    "\n"
   ],
   "id": "8faceb73b3024932",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
