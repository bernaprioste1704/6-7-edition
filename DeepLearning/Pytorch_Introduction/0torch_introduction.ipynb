{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e4b959cb62141a",
   "metadata": {},
   "source": [
    "# Exercises Deep Learning\n",
    "First Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f843372da6ee2f0",
   "metadata": {},
   "source": [
    "## Basic Tensor Operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f59e02c1a624f6b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T17:22:46.590064Z",
     "start_time": "2025-01-14T17:22:45.586928Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d6b1beb874f2d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be071422e88e2797",
   "metadata": {},
   "source": [
    "Different ways to create tensors:\n",
    "- ```torch.zeros```: Creates a tensor filled with zeros\n",
    "- ```torch.ones```: Creates a tensor filled with ones\n",
    "- ```torch.rand```: Creates a tensor with random values uniformly sampled between 0 and 1\n",
    "- ```torch.randn```: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
    "- ```torch.arange```: Creates a tensor containing the values\n",
    "- ```torch.Tensor``` (input list): Creates a tensor from the list elements you provide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652bfdd9d01d2cab",
   "metadata": {},
   "source": [
    "You can obtain the shape of a tensor in the same way as in numpy (```x.shape```), or using the ```.size``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a5aba3abc981603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 3, 4])\n",
      "Size: torch.Size([2, 3, 4])\n",
      "Size: 2 3 4\n"
     ]
    }
   ],
   "source": [
    "shape = x.shape\n",
    "print(\"Shape:\", x.shape)\n",
    "\n",
    "size = x.size()\n",
    "print(\"Size:\", size)\n",
    "\n",
    "dim1, dim2, dim3 = x.size()\n",
    "print(\"Size:\", dim1, dim2, dim3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1919de243a31992c",
   "metadata": {},
   "source": [
    "Tensor to Numpy, and Numpy to Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "788bf302f6590378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array: [[1 2]\n",
      " [3 4]]\n",
      "PyTorch tensor: tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"Numpy array:\", np_arr)\n",
    "print(\"PyTorch tensor:\", tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "20199e8a5e016e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch tensor: tensor([0, 1, 2, 3])\n",
      "Numpy array: [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(4)\n",
    "np_arr = tensor.numpy()\n",
    "\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "print(\"Numpy array:\", np_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e78a94d4c6a5f4",
   "metadata": {},
   "source": [
    "Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6e97615c75ea0e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "x = x.view(2, 3)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8c106a45680668e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
    "print(\"W\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1272a65d6ae9200e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h tensor([[15, 18, 21],\n",
      "        [42, 54, 66]])\n"
     ]
    }
   ],
   "source": [
    "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
    "print(\"h\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721ec6774f26fb13",
   "metadata": {},
   "source": [
    " ### What about gpus?\n",
    "\n",
    "When you create a tensor the tensor is ready to be computed by the cpu. To convert the tensor you can use ```.to()```\n",
    "passing to the function \"cuda\" or \"cpu\" as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b57528335dc0269",
   "metadata": {},
   "source": [
    "#### How do I know if I have cuda cores on my computer?\n",
    "To solve this you can check with torch if cuda is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "38113a46a272b80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Using CPU for PyTorch.\n"
     ]
    }
   ],
   "source": [
    "example_tensor = torch.rand(2,2)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. You can use GPU for PyTorch.\")\n",
    "    example_tensor.to(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU for PyTorch.\")\n",
    "    example_tensor.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8127a2bc83ad170a",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe4a9ddaf9b81d",
   "metadata": {},
   "source": [
    "#### 1. Create two tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964101079da9badd",
   "metadata": {},
   "source": [
    "   - A 3x3 tensor of random numbers.\n",
    "   - A 3x3 tensor filled with ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "83e1b2cdb8bade78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0606, 0.5414, 0.6403],\n",
      "        [0.5293, 0.4150, 0.6887],\n",
      "        [0.4374, 0.2539, 0.1915]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1\n",
    "\n",
    "randTensor = torch.rand(3, 3)\n",
    "oneTensor = torch.ones(3, 3)\n",
    "\n",
    "print(randTensor)\n",
    "print(oneTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271b3d5fb87c50b",
   "metadata": {},
   "source": [
    "#### 2. Perform the following operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db794d8774eae177",
   "metadata": {},
   "source": [
    "- Add the two tensors.\n",
    "- Multiply the two tensors element-wise.\n",
    "- Compute the dot product between the first row of both tensors.\n",
    " - Find the transpose of the resulting tensor from the element-wise multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "406bfe0aed2719b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0606, 1.5414, 1.6403],\n",
      "        [1.5293, 1.4150, 1.6887],\n",
      "        [1.4374, 1.2539, 1.1915]])\n",
      "tensor([[0.0606, 0.5414, 0.6403],\n",
      "        [0.5293, 0.4150, 0.6887],\n",
      "        [0.4374, 0.2539, 0.1915]])\n",
      "tensor(3.7581)\n",
      "tensor([[0.0606, 0.5293, 0.4374],\n",
      "        [0.5414, 0.4150, 0.2539],\n",
      "        [0.6403, 0.6887, 0.1915]])\n"
     ]
    }
   ],
   "source": [
    "#Exercise 2\n",
    "sum =  torch.add(randTensor, oneTensor)\n",
    "print(sum)\n",
    "\n",
    "mul = torch.mul(randTensor, oneTensor)\n",
    "print(mul)\n",
    "\n",
    "dotP = torch.dot(randTensor.view(-1), oneTensor.view(-1))\n",
    "print(dotP)\n",
    "\n",
    "transpose = torch.transpose(mul, 0, 1)\n",
    "print(transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57afe90005dc29a",
   "metadata": {},
   "source": [
    "#### 3. Convert the resulting tensor to a NumPy array and back to a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "182f70f0737cff3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06064802 0.5293475  0.43736166]\n",
      " [0.5413776  0.4150138  0.25391793]\n",
      " [0.6403236  0.68866366 0.19148952]]\n",
      "tensor([[0.0606, 0.5293, 0.4374],\n",
      "        [0.5414, 0.4150, 0.2539],\n",
      "        [0.6403, 0.6887, 0.1915]])\n"
     ]
    }
   ],
   "source": [
    "#Exercise 3\n",
    "\n",
    "npArray = transpose.numpy()\n",
    "print(npArray)\n",
    "\n",
    "transAgain = torch.from_numpy(npArray)\n",
    "print(transAgain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589117b4a2e3f7cb",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d9efcf227bb68",
   "metadata": {},
   "source": [
    "1. Create Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "be5673134b6e6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a = torch.tensor(0., requires_grad=True)\n",
    "x_b = torch.tensor(0., requires_grad=True)\n",
    "w_a = torch.tensor(0.9, requires_grad=True)\n",
    "w_b = torch.tensor(0.9, requires_grad=True)\n",
    "\n",
    "y = torch.tensor(0., requires_grad=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db0554422da0a80",
   "metadata": {},
   "source": [
    "2. Build a computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "35fad594fa32a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_a = w_a * x_a\n",
    "weighted_b = w_b * x_b\n",
    "sum_unit = weighted_a + weighted_b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b928ece0981eb0",
   "metadata": {},
   "source": [
    "3. Activation Function\n",
    "\n",
    "For a simple approach as ease of replication by hand we will this activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cc171048fa0f693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = torch.sigmoid(sum_unit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25082a0d8778158f",
   "metadata": {},
   "source": [
    "4. Calculate Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fea378f48b561f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.BCELoss()\n",
    "output = loss(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b00ba9c0d510c",
   "metadata": {},
   "source": [
    "5. Calculate gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "59e67123bb0c02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2607801d848cb5a",
   "metadata": {},
   "source": [
    "6.Print out the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fe7b458d47eeedab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4500)\n",
      "tensor(0.4500)\n",
      "tensor(0.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(x_a.grad)\n",
    "print(x_b.grad)\n",
    "print(w_a.grad)\n",
    "print(w_b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479bfbd78c7d3e7",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5e7d26b57cd49c3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T17:22:49.794682Z",
     "start_time": "2025-01-14T17:22:49.788011Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "input_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "target_data = torch.tensor([[0], [0], [0], [1]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "122d9dbb9d32cab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T17:22:50.655971Z",
     "start_time": "2025-01-14T17:22:50.652999Z"
    }
   },
   "outputs": [],
   "source": [
    "class ANDGateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANDGateModel, self).__init__()\n",
    "        self.linear = nn.Linear(2, 1,bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "99ae9c0e028670fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T17:24:38.411499Z",
     "start_time": "2025-01-14T17:24:38.375069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.1103\n",
      "Final weights: tensor([[3.6861, 3.6935]])\n",
      "Final bias: tensor([-5.5928])\n",
      "Input: [0. 0.] -> Predicted Output: 0, Raw Output: 0.0037\n",
      "Input: [0. 1.] -> Predicted Output: 0, Raw Output: 0.1302\n",
      "Input: [1. 0.] -> Predicted Output: 0, Raw Output: 0.1294\n",
      "Input: [1. 1.] -> Predicted Output: 1, Raw Output: 0.8565\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = ANDGateModel()\n",
    "\n",
    "# Loss function (Binary Cross-Entropy Loss)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# Optimizer (Stochastic Gradient Descent)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    y_hat = model(input_data)\n",
    "    loss = loss_fn(y_hat, target_data)\n",
    "\n",
    "\n",
    "    loss.backward() # Backpropagation\n",
    "    optimizer.step() # Update parameters using the optimizer\n",
    "    optimizer.zero_grad() # Zero the gradients for the next iteration\n",
    "\n",
    "    # Print loss and progress every 1000 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Final weights and bias (optional)\n",
    "print(f\"Final weights: {model.linear.weight.data}\")\n",
    "print(f\"Final bias: {model.linear.bias.data}\")\n",
    "\n",
    "# Test the AND gate\n",
    "with torch.no_grad():\n",
    "    for i in range(len(input_data)):\n",
    "        x_a, x_b = input_data[i]\n",
    "        y_hat = model(torch.tensor([[x_a, x_b]]))  # Model expects a batch\n",
    "        print(f\"Input: {input_data[i].numpy()} -> Predicted Output: {round(y_hat.item())}, Raw Output: {y_hat.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18785f163f5d7904",
   "metadata": {},
   "source": [
    "!!! IMPORTANT: This example has a significant issue: the test set is the same as the training set.\n",
    "This approach is used here solely for ease of explanation and should never be used in a production environment.!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d64492b0a9f095",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a64599701c601b",
   "metadata": {},
   "source": [
    "#### 1.Replicate the OR Gate using a Neural Network\n",
    " Objective:\n",
    "- Train a neural network to approximate the function of an OR gate.\n",
    "- Compare how changing the weights or biases impacts the output of the network.\n",
    "\n",
    "Input 1 | Input 2 | Output (OR)\n",
    "| -- | -- | --|\n",
    "0 | 0 | 0\n",
    "0 | 1 | 1\n",
    "1 | 0 | 1\n",
    "1 | 1 | 1\n",
    "\n",
    "1. Create the dataset\n",
    "2. Replicate the architecture from the AND gate example\n",
    "3. Change the loss function from Binary Cross-Entropy to Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a197f7d767d46a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Here\n",
    "\n",
    "class ORGateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ORGateModel, self).__init__()\n",
    "        self.linear = nn.Linear(2, 1,bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6c033bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0113\n",
      "Final weights: tensor([[3.9011, 3.9587]])\n",
      "Final bias: tensor([-5.9280])\n",
      "Input: [0. 0.] -> Predicted Output: 0, Raw Output: 0.0027\n",
      "Input: [0. 1.] -> Predicted Output: 0, Raw Output: 0.1225\n",
      "Input: [1. 0.] -> Predicted Output: 0, Raw Output: 0.1164\n",
      "Input: [1. 1.] -> Predicted Output: 1, Raw Output: 0.8735\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = ORGateModel()\n",
    "\n",
    "# Loss function (Binary Cross-Entropy Loss)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Optimizer (Stochastic Gradient Descent)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    y_hat = model(input_data)\n",
    "    loss = loss_fn(y_hat, target_data)\n",
    "\n",
    "\n",
    "    loss.backward() # Backpropagation\n",
    "    optimizer.step() # Update parameters using the optimizer\n",
    "    optimizer.zero_grad() # Zero the gradients for the next iteration\n",
    "\n",
    "    # Print loss and progress every 1000 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Final weights and bias (optional)\n",
    "print(f\"Final weights: {model.linear.weight.data}\")\n",
    "print(f\"Final bias: {model.linear.bias.data}\")\n",
    "\n",
    "# Test the AND gate\n",
    "with torch.no_grad():\n",
    "    for i in range(len(input_data)):\n",
    "        x_a, x_b = input_data[i]\n",
    "        y_hat = model(torch.tensor([[x_a, x_b]]))  # Model expects a batch\n",
    "        print(f\"Input: {input_data[i].numpy()} -> Predicted Output: {round(y_hat.item())}, Raw Output: {y_hat.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7c401a9cd9bd0be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc0ab91a8ed899",
   "metadata": {},
   "source": [
    "#### 2. Build and train a network\n",
    "1. Build a simple fully connected neural network with the following architecture:\n",
    "    - Input layer with 2 units\n",
    "    - Hidden layer with 4 units and ReLU activation\n",
    "    - Output layer with 1 unit\n",
    "2. Define the following loss function and optimizer:\n",
    "    - Loss: Mean Squared Error (MSE)\n",
    "    - Optimizer: Stochastic Gradient Descent (SGD)\n",
    "\n",
    "The network should mimic $y = 2x_1 + 3x_2$, where $x_1$ and $x_2$ are random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8faceb73b3024932",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1415340237.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[120], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.layer1 =   # Input to hidden layer\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # Define layers here\n",
    "        self.layer1 =   # Input to hidden layer\n",
    "        self.activation_function =   # Activation function\n",
    "        self.layer2 =   # Hidden to output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define forward pass\n",
    "        x =\n",
    "        x =\n",
    "        x =\n",
    "        return x\n",
    "\n",
    "# Create synthetic data\n",
    "x = torch.rand(100, 2)\n",
    "y = 2 * x[:, 0] + 3 * x[:, 1]\n",
    "y = y.view(-1, 1)\n",
    "\n",
    "# Split data into training and test sets (80% train, 20% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleNet()\n",
    "criterion =   # Loss function (MSE)\n",
    "optimizer =   # Optimizer (SGD)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    # Compute loss\n",
    "    loss =   # Compute loss using criterion\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(x_test)  # Get predictions for the test set\n",
    "    test_loss = criterion(y_test_pred, y_test)  # Compute test loss\n",
    "\n",
    "    print(f'Test Loss: {test_loss.item()}')\n",
    "\n",
    "# Show some final predictions\n",
    "print(\"Final Predictions (first 5 test samples):\")\n",
    "for i in range(5):\n",
    "    print(f\"Predicted: {y_test_pred[i].item():.4f}, Actual: {y_test[i].item():.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
