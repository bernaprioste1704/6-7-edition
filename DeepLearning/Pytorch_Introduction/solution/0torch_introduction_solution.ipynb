{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exercises Deep Learning\n",
    "First Lecture"
   ],
   "id": "40e4b959cb62141a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Basic Tensor Operations\n",
   "id": "f843372da6ee2f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:40:55.941803Z",
     "start_time": "2025-01-14T15:40:55.939627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn"
   ],
   "id": "f59e02c1a624f6b9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Different ways to create tensors:\n",
    "- ```torch.zeros```: Creates a tensor filled with zeros\n",
    "- ```torch.ones```: Creates a tensor filled with ones\n",
    "- ```torch.rand```: Creates a tensor with random values uniformly sampled between 0 and 1\n",
    "- ```torch.randn```: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
    "- ```torch.arange```: Creates a tensor containing the values\n",
    "- ```torch.Tensor``` (input list): Creates a tensor from the list elements you provide"
   ],
   "id": "be071422e88e2797"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can obtain the shape of a tensor in the same way as in numpy (```x.shape```), or using the ```.size``` method:",
   "id": "652bfdd9d01d2cab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:41:30.158162Z",
     "start_time": "2025-01-14T15:41:30.155716Z"
    }
   },
   "cell_type": "code",
   "source": "x = torch.Tensor(2, 3, 4)",
   "id": "ce06fc30f0bdb563",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:41:47.809112Z",
     "start_time": "2025-01-14T15:41:47.807072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shape = x.shape\n",
    "print(\"Shape:\", x.shape)\n",
    "\n",
    "size = x.size()\n",
    "print(\"Size:\", size)"
   ],
   "id": "3a5aba3abc981603",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 3, 4])\n",
      "Size: torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tensor to Numpy, and Numpy to Tensor\n",
   "id": "1919de243a31992c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"Numpy array:\", np_arr)\n",
    "print(\"PyTorch tensor:\", tensor)"
   ],
   "id": "788bf302f6590378",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tensor = torch.arange(4)\n",
    "np_arr = tensor.numpy()\n",
    "\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "print(\"Numpy array:\", np_arr)"
   ],
   "id": "20199e8a5e016e34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Matrix multiplication",
   "id": "f0e78a94d4c6a5f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = torch.arange(6)\n",
    "x = x.view(2, 3)\n",
    "print(\"X\", x)"
   ],
   "id": "6e97615c75ea0e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
    "print(\"W\", W)"
   ],
   "id": "d8c106a45680668e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
    "print(\"h\", h)"
   ],
   "id": "1272a65d6ae9200e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " ### What about gpus?\n",
    "\n",
    "When you create a tensor the tensor is ready to be computed by the cpu. To convert the tensor you can use ```.to()```\n",
    "passing to the function \"cuda\" or \"cpu\" as needed"
   ],
   "id": "721ec6774f26fb13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### How do I know if I have cuda cores on my computer?\n",
    "To solve this you can check with torch if cuda is available:"
   ],
   "id": "3b57528335dc0269"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "example_tensor = torch.rand(2,2)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. You can use GPU for PyTorch.\")\n",
    "    example_tensor.to(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU for PyTorch.\")\n",
    "    example_tensor.to(\"cpu\")"
   ],
   "id": "38113a46a272b80a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exercises",
   "id": "8127a2bc83ad170a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Create two tensors",
   "id": "dbbe4a9ddaf9b81d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "   - A 3x3 tensor of random numbers.\n",
    "   - A 3x3 tensor filled with ones."
   ],
   "id": "964101079da9badd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:35:04.307529Z",
     "start_time": "2025-01-14T15:35:04.304407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.rand(3, 3)\n",
    "b = torch.ones(3, 3)"
   ],
   "id": "83e1b2cdb8bade78",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Perform the following operations",
   "id": "a271b3d5fb87c50b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Add the two tensors.\n",
    "- Multiply the two tensors element-wise.\n",
    "- Compute the dot product between the first row of both tensors.\n",
    " - Find the transpose of the resulting tensor from the element-wise multiplication."
   ],
   "id": "db794d8774eae177"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:35:05.508776Z",
     "start_time": "2025-01-14T15:35:05.504903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c = a + b\n",
    "d = a * b\n",
    "e = torch.dot(a[0], b[0])\n",
    "f = b.t()"
   ],
   "id": "406bfe0aed2719b2",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Convert the resulting tensor to a NumPy array and back to a PyTorch tensor.",
   "id": "a57afe90005dc29a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch_tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "numpy_array = torch_tensor.numpy()\n",
    "print(torch_tensor)\n",
    "print(numpy_array)"
   ],
   "id": "efb38c1c83b6ad8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:38:49.481580Z",
     "start_time": "2025-01-14T15:38:49.478445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch_tensor_back = torch.from_numpy(numpy_array)\n",
    "print(torch_tensor_back)"
   ],
   "id": "182f70f0737cff3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Autograd\n",
    "```torch.autograd``` is PyTorchâ€™s automatic differentiation engine that powers neural network training.\n"
   ],
   "id": "589117b4a2e3f7cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Create Tensors",
   "id": "a16d9efcf227bb68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:40:39.656991Z",
     "start_time": "2025-01-14T15:40:39.642847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_a = torch.tensor(0., requires_grad=True)\n",
    "x_b = torch.tensor(0., requires_grad=True)\n",
    "w_a = torch.tensor(0.9, requires_grad=True)\n",
    "w_b = torch.tensor(0.9, requires_grad=True)\n",
    "\n",
    "y = torch.tensor(0., requires_grad=False)"
   ],
   "id": "be5673134b6e6eec",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Build a computation graph",
   "id": "1db0554422da0a80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:40:40.469066Z",
     "start_time": "2025-01-14T15:40:40.466065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weighted_a = w_a * x_a\n",
    "weighted_b = w_b * x_b\n",
    "sum_unit = weighted_a + weighted_b"
   ],
   "id": "35fad594fa32a16c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. Activation Function\n",
    "\n",
    "For a simple approach as ease of replication by hand we will this activation function:"
   ],
   "id": "89b928ece0981eb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:40:41.270687Z",
     "start_time": "2025-01-14T15:40:41.267329Z"
    }
   },
   "cell_type": "code",
   "source": "y_hat = torch.sigmoid(sum_unit)",
   "id": "cc171048fa0f693d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Calculate Loss",
   "id": "25082a0d8778158f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:40:42.237343Z",
     "start_time": "2025-01-14T15:40:42.232370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = torch.nn.BCELoss()\n",
    "output = loss(y_hat, y)\n"
   ],
   "id": "fea378f48b561f17",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. Calculate gradients",
   "id": "da4b00ba9c0d510c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:40:43.080798Z",
     "start_time": "2025-01-14T15:40:43.055283Z"
    }
   },
   "cell_type": "code",
   "source": "output.backward()",
   "id": "59e67123bb0c02f9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6.Print out the gradients",
   "id": "d2607801d848cb5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:40:43.969437Z",
     "start_time": "2025-01-14T15:40:43.965388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(x_a.grad)\n",
    "print(x_b.grad)\n",
    "print(w_a.grad)\n",
    "print(w_b.grad)"
   ],
   "id": "fe7b458d47eeedab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4500)\n",
      "tensor(0.4500)\n",
      "tensor(0.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Loop",
   "id": "e479bfbd78c7d3e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:40:46.261018Z",
     "start_time": "2025-01-14T15:40:46.257828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "input_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "target_data = torch.tensor([[0], [0], [0], [1]], dtype=torch.float32)"
   ],
   "id": "5e7d26b57cd49c3e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:42:02.302412Z",
     "start_time": "2025-01-14T15:42:02.295612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ANDGateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANDGateModel, self).__init__()\n",
    "        self.linear = nn.Linear(2, 1,bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n"
   ],
   "id": "122d9dbb9d32cab2",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:42:05.762729Z",
     "start_time": "2025-01-14T15:42:03.629805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model = ANDGateModel()\n",
    "\n",
    "# Loss function (Binary Cross-Entropy Loss)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# Optimizer (Stochastic Gradient Descent)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    y_hat = model(input_data)\n",
    "    loss = loss_fn(y_hat, target_data)\n",
    "\n",
    "\n",
    "    loss.backward() # Backpropagation\n",
    "    optimizer.step() # Update parameters using the optimizer\n",
    "    optimizer.zero_grad() # Zero the gradients for the next iteration\n",
    "\n",
    "    # Print loss and progress every 1000 epochs\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Final weights and bias (optional)\n",
    "print(f\"Final weights: {model.linear.weight.data}\")\n",
    "print(f\"Final bias: {model.linear.bias.data}\")\n",
    "\n",
    "# Test the AND gate\n",
    "with torch.no_grad():\n",
    "    for i in range(len(input_data)):\n",
    "        x_a, x_b = input_data[i]\n",
    "        y_hat = model(torch.tensor([[x_a, x_b]]))  # Model expects a batch\n",
    "        print(f\"Input: {input_data[i].numpy()} -> Predicted Output: {round(y_hat.item())}, Raw Output: {y_hat.item():.4f}\")\n"
   ],
   "id": "99ae9c0e028670fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final weights: tensor([[3.6639, 3.6537]])\n",
      "Final bias: tensor([-5.4969])\n",
      "Input: [0. 0.] -> Predicted Output: 0, Raw Output: 0.0041\n",
      "Input: [0. 1.] -> Predicted Output: 0, Raw Output: 0.1367\n",
      "Input: [1. 0.] -> Predicted Output: 0, Raw Output: 0.1379\n",
      "Input: [1. 1.] -> Predicted Output: 1, Raw Output: 0.8606\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exercises",
   "id": "38d64492b0a9f095"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1.Replicate the OR Gate using a Neural Network\n",
    " Objective:\n",
    "- Train a neural network to approximate the function of an OR gate.\n",
    "- Compare how changing the weights or biases impacts the output of the network.\n",
    "\n",
    "Input 1 | Input 2 | Output (OR)\n",
    "| -- | -- | --|\n",
    "0 | 0 | 0\n",
    "0 | 1 | 1\n",
    "1 | 0 | 1\n",
    "1 | 1 | 1\n",
    "\n",
    "1. Create the dataset\n",
    "2. Replicate the architecture from the AND gate example\n",
    "3. Change the loss function from Binary Cross-Entropy to Mean Squared Error"
   ],
   "id": "4a64599701c601b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Code Here",
   "id": "a197f7d767d46a18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html",
   "id": "7c401a9cd9bd0be5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2. Build and train a network\n",
    "1. Build a simple fully connected neural network with the following architecture:\n",
    "    - Input layer with 2 units\n",
    "    - Hidden layer with 4 units and ReLU activation\n",
    "    - Output layer with 1 unit\n",
    "2. Define the following loss function and optimizer:\n",
    "    - Loss: Mean Squared Error (MSE)\n",
    "    - Optimizer: Stochastic Gradient Descent (SGD)"
   ],
   "id": "86fc0ab91a8ed899"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:48:31.808232Z",
     "start_time": "2025-01-14T15:48:31.780434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # Define layers here\n",
    "        self.layer1 = nn.Linear(2, 4)\n",
    "        self.activation_function = nn.ReLU()\n",
    "        self.layer2 =   nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define forward pass\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation_function(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# Create synthetic data\n",
    "x_train = torch.rand(100, 2)\n",
    "y_train = 2 * x_train[:, 0] + 3 * x_train[:, 1]\n",
    "y_train = y_train.view(-1, 1)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Final model predictions\n",
    "print(\"Final Predictions:\", model(x_train[:5]))\n",
    "print(\"Actual Values:\", y_train[:5])\n"
   ],
   "id": "8faceb73b3024932",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 5.695849418640137\n",
      "Epoch 20, Loss: 2.8809168338775635\n",
      "Epoch 30, Loss: 1.3397232294082642\n",
      "Epoch 40, Loss: 0.8157290816307068\n",
      "Epoch 50, Loss: 0.6970154643058777\n",
      "Epoch 60, Loss: 0.6625199913978577\n",
      "Epoch 70, Loss: 0.6401515007019043\n",
      "Epoch 80, Loss: 0.6194170117378235\n",
      "Epoch 90, Loss: 0.5990427136421204\n",
      "Epoch 100, Loss: 0.5788787007331848\n",
      "Final Predictions: tensor([[2.2517],\n",
      "        [2.8239],\n",
      "        [2.6435],\n",
      "        [2.6913],\n",
      "        [2.9278]], grad_fn=<AddmmBackward0>)\n",
      "Actual Values: tensor([[1.1961],\n",
      "        [2.3344],\n",
      "        [2.5772],\n",
      "        [2.6616],\n",
      "        [3.3427]])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "853579f3c211d43f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
